{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ0ZKrDxffoG"
   },
   "source": [
    "#**Experiment 4**\n",
    "\n",
    "Implement an image classification task using pre-trained models like VGGNet, InceptionNet and ResNet and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztyo3kPb9WtR"
   },
   "source": [
    "# Description\n",
    "\n",
    "complete description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m18N2Wwh9aKd"
   },
   "source": [
    "# Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JuKSi3EJyGb-"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import Input\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras import applications\n",
    "# from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import  Dense, Flatten, Conv2D, MaxPooling2D\n",
    "# from keras.preprocessing import image\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "# from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHnd3rrLLql4"
   },
   "source": [
    "#**Loading the Training and Testing Data and Defining the Basic Parameters**\n",
    "* About data: https://data.mendeley.com/datasets/tywbtsjrjv/1\n",
    "\n",
    "Download this data: https://drive.google.com/drive/folders/131DwMyAkwR_F4A_XFQdsaDYXuXF5m4pr?usp=sharing\n",
    "\n",
    "* We are resizing the input image to 128 * 128\n",
    "\n",
    "* In the dataset :\n",
    "    Training Set : 70%\n",
    "    Validation Set : 20%\n",
    "    Test Set : 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "506y_hn8v6m_"
   },
   "outputs": [],
   "source": [
    "!unzip \"plant_villa ge.zip\" -d \"plant_village\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyYRaHdLavO2"
   },
   "outputs": [],
   "source": [
    "# Normalize training and validation data in the range of 0 to 1\n",
    "train_datagen = ImageDataGenerator(rescale=1/255) # vertical_flip=True,\n",
    "                                                   # horizontal_flip=True,\n",
    "                                                   # height_shift_range=0.1,\n",
    "                                                   # width_shift_range=0.1\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Read the training sample and set the batch size\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'plant_village/plant_village/train/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Read Validation data from directory and define target size with batch size\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'plant_village/plant_village/val/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'plant_village/plant_village/test/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwNwRorH8g2W"
   },
   "source": [
    "# **Visualization of Few Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZsBwS0oavRB"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 16))\n",
    "for i in range(1, 17):\n",
    "  plt.subplot(4, 4, i)\n",
    "  img, label = test_generator.next()\n",
    "  # print(img.shape)\n",
    "  # print(label)\n",
    "  plt.imshow(img[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AheZPiNC6ZwZ"
   },
   "outputs": [],
   "source": [
    "img, label = test_generator.next()\n",
    "img[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trLy4hiwGDvM"
   },
   "source": [
    "#**What is ImageNet?**\n",
    "ImageNet is formally a project aimed at (manually) labeling and categorizing images into almost 22,000 separate object categories for the purpose of computer vision research.\n",
    "\n",
    "However, when we hear the term “ImageNet” in the context of deep learning and Convolutional Neural Networks, we are likely referring to the ImageNet Large Scale Visual Recognition Challenge, or ILSVRC for short.\n",
    "\n",
    "The goal of this image classification challenge is to train a model that can correctly classify an input image into 1,000 separate object categories.\n",
    "\n",
    "Models are trained on ~1.2 million training images with another 50,000 images for validation and 100,000 images for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiJvRIxN5P9D"
   },
   "source": [
    "# **Exploring Keras Applications for Transfer Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btHo6pJ_7H-K"
   },
   "source": [
    "## **VGG16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hANcs-MT5mCz"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape= (128, 128, 3)) # Include_top = False means excluding the model fully connected layers\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQVsgppw8rSl"
   },
   "source": [
    "# **Adding top layers according to number of classes in our data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HcQlsbI6_eB"
   },
   "outputs": [],
   "source": [
    "flatten_layer = layers.GlobalAveragePooling2D()\n",
    "prediction_layer = layers.Dense(4, activation='softmax')\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    flatten_layer,\n",
    "    prediction_layer\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5D4zLWQ8qd8"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg3w-8oa6_gR"
   },
   "outputs": [],
   "source": [
    "# We are going to use accuracy metrics and cross entropy loss as performance parameters\n",
    "model.compile(optimizer = Adam(learning_rate = 0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "# Train the model\n",
    "history = model.fit(train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNlnbyvA-tQq"
   },
   "source": [
    "# **Saving the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UNr-4ev66_iU"
   },
   "outputs": [],
   "source": [
    "model.save(\"VGG16_plant_deseas.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mW434s0y-wZL"
   },
   "source": [
    "# **Loading the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxLxfO_E-UJ7"
   },
   "outputs": [],
   "source": [
    "model = models.load_model('VGG16_plant_deseas.h5')\n",
    "print(\"Model is loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQtU5xt6-82y"
   },
   "source": [
    "# **Visualization of training over epoch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHOu1OtA86RJ"
   },
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc0bkO6H6_kq"
   },
   "outputs": [],
   "source": [
    "epochs = range(len(train_acc))\n",
    "plt.plot(epochs, train_acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'g', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'g', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0o2y_gT_Cjy"
   },
   "source": [
    "# **Performance measure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9Az0ym5-jbf"
   },
   "outputs": [],
   "source": [
    "# Get the filenames from the generator\n",
    "fnames = test_generator.filenames\n",
    "\n",
    "# Get the ground truth from generator\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "# Get the label to class mapping from the generator\n",
    "label2index = test_generator.class_indices\n",
    "\n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict((v,k) for k,v in label2index.items())\n",
    "\n",
    "# Get the predictions from the model using the generator\n",
    "predictions = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size,verbose=1)\n",
    "predicted_classes = np.argmax(predictions,axis=1)\n",
    "\n",
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DE67ci3Iv9c"
   },
   "outputs": [],
   "source": [
    "accuracy = ((test_generator.samples-len(errors))/test_generator.samples) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4w-fuWoSv6nV"
   },
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vDoTCwsT-jdZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "cm = confusion_matrix(y_true=ground_truth, y_pred=predicted_classes)\n",
    "cm = np.array(cm)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=label2index, yticklabels=label2index, cmap=\"YlGnBu\")\n",
    "plt.ylabel('Actual', fontsize=15)\n",
    "plt.xlabel('Predicted', fontsize=15)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "miprwgWd-jfs"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ground_truth, predicted_classes, target_names=label2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Etw2kJgzFxmF"
   },
   "source": [
    "# **InceptionNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "An2kwn-a-jjn"
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "\n",
    "## Loading InceptionV3 model\n",
    "base_model = applications.InceptionV3(weights=\"imagenet\", include_top=False, input_shape= (128, 128, 3))\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IStUTSvcJ-uV"
   },
   "outputs": [],
   "source": [
    "# include GlobalAveragePooling2D\n",
    "\n",
    "# include final Dense layer\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5t40MvBCKC02"
   },
   "outputs": [],
   "source": [
    "# Compile model with Adam Optimizer (learning_rate = 0.001), categorical_crossentropy loss, accuracy metric\n",
    "\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkagJbtAKS82"
   },
   "outputs": [],
   "source": [
    "# Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-KZZdVqKS-8"
   },
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QfvHtrUvKTA7"
   },
   "outputs": [],
   "source": [
    "# Display loss/accuracies vs epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsBeZgZjKTC2"
   },
   "outputs": [],
   "source": [
    "# Get the filenames from the generator\n",
    "#fnames = test_generator.filenames\n",
    "\n",
    "# Get the ground truth from generator\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "# Get the label to class mapping from the generator\n",
    "label2index = test_generator.class_indices\n",
    "\n",
    "# Get the predictions from the model using the generator\n",
    "predictions = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size,verbose=1)\n",
    "predicted_classes = np.argmax(predictions,axis=1)\n",
    "\n",
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yczkgSjAKxOZ"
   },
   "outputs": [],
   "source": [
    "accuracy = ((test_generator.samples-len(errors))/test_generator.samples) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtyOx0W-KxYK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "cm = confusion_matrix(y_true=ground_truth, y_pred=predicted_classes)\n",
    "cm = np.array(cm)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=label2index, yticklabels=label2index, cmap=\"YlGnBu\")\n",
    "plt.ylabel('Actual', fontsize=15)\n",
    "plt.xlabel('Predicted', fontsize=15)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFrironHKxaB"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ground_truth, predicted_classes, target_names=label2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlZTFzq4LEAt"
   },
   "source": [
    "#**ResNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBTdSU6GL_mr"
   },
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = applications.ResNet50(weights=\"imagenet\", include_top=False, input_shape= (128, 128, 3))\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YErXMvxXMFgi"
   },
   "outputs": [],
   "source": [
    "# include GlobalAveragePooling2D\n",
    "\n",
    "# include final Dense layer\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g15e5z3WKTJR"
   },
   "outputs": [],
   "source": [
    "# Compile model with Adam Optimizer (learning_rate = 0.001), categorical_crossentropy loss, accuracy metric\n",
    "\n",
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ULc2T2mgKTLA"
   },
   "outputs": [],
   "source": [
    "# Save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StfAuMLuKfCi"
   },
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKGbd7lvKfEY"
   },
   "outputs": [],
   "source": [
    "# Display loss/accuracies vs epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9UL05zbKfGR"
   },
   "outputs": [],
   "source": [
    "# Get the filenames from the generator\n",
    "#fnames = test_generator.filenames\n",
    "\n",
    "# Get the ground truth from generator\n",
    "ground_truth = test_generator.classes\n",
    "\n",
    "# Get the label to class mapping from the generator\n",
    "label2index = test_generator.class_indices\n",
    "\n",
    "# Getting the mapping from class index to class label\n",
    "#idx2label = dict((v,k) for k,v in label2index.items())\n",
    "\n",
    "# Get the predictions from the model using the generator\n",
    "predictions = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size,verbose=1)\n",
    "predicted_classes = np.argmax(predictions,axis=1)\n",
    "\n",
    "errors = np.where(predicted_classes != ground_truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxXivh_jKfIg"
   },
   "outputs": [],
   "source": [
    "accuracy = ((test_generator.samples-len(errors))/test_generator.samples) * 100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1-Cw2BiKfL0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "cm = confusion_matrix(y_true=ground_truth, y_pred=predicted_classes)\n",
    "cm = np.array(cm)\n",
    "# Normalise\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f', xticklabels=label2index, yticklabels=label2index, cmap=\"YlGnBu\")\n",
    "plt.ylabel('Actual', fontsize=15)\n",
    "plt.xlabel('Predicted', fontsize=15)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-jcVMDfKTND"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(ground_truth, predicted_classes, target_names=label2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ej9ywjlMCiqD"
   },
   "source": [
    "# Conclusion\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
