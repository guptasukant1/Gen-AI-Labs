{"cells":[{"cell_type":"markdown","metadata":{"id":"JbLj-OUKojSL"},"source":["# **AIM: Build an Artificial Neural Network to implement Binary Classification task using the Back-propagation algorithm and test the same using appropriate data sets.**"]},{"cell_type":"markdown","metadata":{"id":"GAd5BOpNn1yb"},"source":["# **Description**\n","\n","The data used here is : '**Pima Indians Diabetes Dataset**'. It is downloaded from : https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\n","\n","It is a binary (2-class) classification problem. There are 768 observations with 8 input variables and 1 output variable.\n","\n","The variable names are as follows:\n","\n","**1. Number of times pregnant.**\n","\n","**2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.**\n","\n","**3. Diastolic blood pressure (mm Hg).**\n","\n","**4. Triceps skinfold thickness (mm).**\n","\n","**5. 2-Hour serum insulin (mu U/ml).**\n","\n","**6. Body mass index (weight in kg/(height in m)^2).**\n","\n","**7. Diabetes pedigree function.**\n","\n","**8. Age (years).**\n","\n","**9. Class variable (0 or 1).**\n"]},{"cell_type":"markdown","metadata":{"id":"c3pOyaANmimQ"},"source":[" # **Data Import and Processing**\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"mwGyz6EwSRk5"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import sklearn"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"-n1H04B-dX7O"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 768 entries, 0 to 767\n","Data columns (total 9 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   0       768 non-null    int64  \n"," 1   1       768 non-null    int64  \n"," 2   2       768 non-null    int64  \n"," 3   3       768 non-null    int64  \n"," 4   4       768 non-null    int64  \n"," 5   5       768 non-null    float64\n"," 6   6       768 non-null    float64\n"," 7   7       768 non-null    int64  \n"," 8   8       768 non-null    int64  \n","dtypes: float64(2), int64(7)\n","memory usage: 54.1 KB\n","None\n","   0    1   2   3    4     5      6   7  8\n","0  6  148  72  35    0  33.6  0.627  50  1\n","1  1   85  66  29    0  26.6  0.351  31  0\n","2  8  183  64   0    0  23.3  0.672  32  1\n","3  1   89  66  23   94  28.1  0.167  21  0\n","4  0  137  40  35  168  43.1  2.288  33  1\n"]}],"source":["# load data\n","url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv'\n","data_pd = pd.read_csv(url,header = None)\n","print(data_pd.info())\n","print(data_pd.head())"]},{"cell_type":"markdown","metadata":{"id":"jsRaWD3y5CgE"},"source":["StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qyy2Qp8uHNkQ"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.639947</td>\n","      <td>0.848324</td>\n","      <td>0.149641</td>\n","      <td>0.907270</td>\n","      <td>-0.692891</td>\n","      <td>0.204013</td>\n","      <td>0.468492</td>\n","      <td>1.425995</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.844885</td>\n","      <td>-1.123396</td>\n","      <td>-0.160546</td>\n","      <td>0.530902</td>\n","      <td>-0.692891</td>\n","      <td>-0.684422</td>\n","      <td>-0.365061</td>\n","      <td>-0.190672</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.233880</td>\n","      <td>1.943724</td>\n","      <td>-0.263941</td>\n","      <td>-1.288212</td>\n","      <td>-0.692891</td>\n","      <td>-1.103255</td>\n","      <td>0.604397</td>\n","      <td>-0.105584</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.844885</td>\n","      <td>-0.998208</td>\n","      <td>-0.160546</td>\n","      <td>0.154533</td>\n","      <td>0.123302</td>\n","      <td>-0.494043</td>\n","      <td>-0.920763</td>\n","      <td>-1.041549</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-1.141852</td>\n","      <td>0.504055</td>\n","      <td>-1.504687</td>\n","      <td>0.907270</td>\n","      <td>0.765836</td>\n","      <td>1.409746</td>\n","      <td>5.484909</td>\n","      <td>-0.020496</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          0         1         2         3         4         5         6  \\\n","0  0.639947  0.848324  0.149641  0.907270 -0.692891  0.204013  0.468492   \n","1 -0.844885 -1.123396 -0.160546  0.530902 -0.692891 -0.684422 -0.365061   \n","2  1.233880  1.943724 -0.263941 -1.288212 -0.692891 -1.103255  0.604397   \n","3 -0.844885 -0.998208 -0.160546  0.154533  0.123302 -0.494043 -0.920763   \n","4 -1.141852  0.504055 -1.504687  0.907270  0.765836  1.409746  5.484909   \n","\n","          7  \n","0  1.425995  \n","1 -0.190672  \n","2 -0.105584  \n","3 -1.041549  \n","4 -0.020496  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#Scaling Numerical columns\n","from sklearn.preprocessing import StandardScaler\n","std = StandardScaler()\n","scaled = std.fit_transform(data_pd.iloc[:,0:8])\n","scaled = pd.DataFrame(scaled)\n","scaled.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"aSvqBd1jC0GW"},"outputs":[{"name":"stdout","output_type":"stream","text":["X_data: (768, 8)\n","Y_data: (768,)\n"]}],"source":["X_data =scaled.to_numpy()\n","print('X_data:',np.shape(X_data))\n","Y_data = data_pd.iloc[:,8]\n","print('Y_data:',np.shape(Y_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"re5mYzfAdX2R"},"outputs":[],"source":["# Split data into X_train, X_test, y_train, y_test\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.25, random_state= 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6XY9nsL8dXzm"},"outputs":[],"source":["# Check the dimension of the sets\n","print('X_train:',np.shape(X_train))\n","print('y_train:',np.shape(y_train))\n","print('X_test:',np.shape(X_test))\n","print('y_test:',np.shape(y_test))"]},{"cell_type":"markdown","metadata":{"id":"5hDbfl4qm5Iq"},"source":["# **Design the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTOChYlGdXmu"},"outputs":[],"source":["import keras\n","from keras.models import Sequential   # importing Sequential model\n","from keras.layers import Dense        # importing Dense layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRvrz_MLSfMd"},"outputs":[],"source":["# declaring model\n","basic_model = Sequential()"]},{"cell_type":"markdown","metadata":{"id":"yX8XB64P4IqQ"},"source":["Check Eg: https://github.com/urjeet/Pima-Diabetes-Keras-Model/blob/master/pima_diabetes_keras_model.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1uhibQNlWsPU"},"outputs":[],"source":["# Adding layers to the model (DIY)\n","\n","# First layers: 8 neurons/perceptrons that takes the input and uses 'sigmoid' activation function.\n","\n","# Second layers: 4 neurons/perceptrons, 'sigmoid' activation function.\n","\n","# Final layer: 1 neuron/perceptron to do binary classification\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1_pihhdiTlHR"},"outputs":[],"source":["# compiling the model (DIY)\n"]},{"cell_type":"markdown","metadata":{"id":"1u-JSWmXnAqf"},"source":["# **Train the Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvTzUK7OasqW"},"outputs":[],"source":["# training the model\n","epochs=120\n","history = basic_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=epochs)"]},{"cell_type":"markdown","metadata":{"id":"Sb996_yGu6cl"},"source":["#**Evaluate the Model**"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"SUS1fZ5nvF3U"},"outputs":[{"ename":"NameError","evalue":"name 'epochs' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# plot loss vs epochs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m epochRange \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[43mepochs\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m);\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochRange,history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochRange,history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"]}],"source":["# plot loss vs epochs\n","epochRange = range(1,epochs+1);\n","plt.plot(epochRange,history.history['loss'])\n","plt.plot(epochRange,history.history['val_loss'])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.grid()\n","plt.xlim((1,epochs))\n","plt.legend(['Train','Test'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z08lfMC5v0wk"},"outputs":[],"source":["# Plot accuracy vs epochs (DIY)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FlT5Vst5h16C"},"outputs":[],"source":["# Test, Loss and accuracy\n","loss_and_metrics = basic_model.evaluate(X_test, y_test)\n","print('Loss = ',loss_and_metrics[0])\n","print('Accuracy = ',loss_and_metrics[1])"]},{"cell_type":"markdown","metadata":{"id":"rs-Eo3bFwsl_"},"source":["## Classification Model Performance measures\n","\n","<img src='https://editor.analyticsvidhya.com/uploads/99666confusion%20matrix.JPG' width=40%>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8j6D_uvwu1p"},"outputs":[],"source":["y_pred = basic_model.predict(X_test)\n","print(y_test[:5])\n","print(y_pred[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Dg5IIQNx2Wy"},"outputs":[],"source":["y_pred =[1 if y_pred[aa]>=0.5 else 0 for aa in range(len(y_pred)) ]\n","print(y_pred[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BtqHcIgEkn0l"},"outputs":[],"source":["print(sklearn.metrics.classification_report(y_test, y_pred))"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/Kaustubh-Atey/Keras-Codes-/blob/master/Keras%20-%20Binary%20Classification.ipynb","timestamp":1690785277040}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
